<br>

<div align="center">
    <a href="README.md">ðŸ‡ºðŸ‡¸ English</a> | <a href="README.pt-br.md">ðŸ‡§ðŸ‡· PortuguÃªs (Brasil)</a>
</div>
<br>

# ðŸ” Stack LGTM para Kubernetes

## SumÃ¡rio

- [IntroduÃ§Ã£o](#introduÃ§Ã£o)
  - [Arquitetura](#arquitetura)
  - [Requisitos de Hardware](#requisitos-de-hardware)
- [InÃ­cio RÃ¡pido](#-inÃ­cio-rÃ¡pido)
  - [PrÃ©-requisitos](#-prÃ©-requisitos)
  - [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
    - [OpÃ§Ã£o 1: Makefile](#opÃ§Ã£o-1-makefile)
    - [OpÃ§Ã£o 2: InstalaÃ§Ã£o Manual](#opÃ§Ã£o-2-instalaÃ§Ã£o-manual)
      - [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)
      - [Escolha seu Ambiente](#escolha-seu-ambiente)
        - [Local](#local-k3s-minikube)
        - [ConfiguraÃ§Ã£o para ProduÃ§Ã£o na GCP](#configuraÃ§Ã£o-para-produÃ§Ã£o-na-gcp)
- [InstalaÃ§Ã£o de DependÃªncias](#instalaÃ§Ã£o-de-dependÃªncias-opcional)
- [Testando](#testando)
  - [Acesso ao Grafana](#acesso-ao-grafana)
  - [Enviando Dados](#enviando-dados)
    - [Loki (Logs)](#loki-logs)
    - [Tempo (Traces)](#tempo-traces)
    - [Mimir (MÃ©tricas)](#mimir-mÃ©tricas)
- [OpenTelemetry](#opentelemetry)
  - [OpenTelemetry Collector](#opentelemetry-collector)
  - [IntegraÃ§Ã£o com Flask App](#integraÃ§Ã£o-com-flask-app)
  - [Testando a IntegraÃ§Ã£o](#testando-a-integraÃ§Ã£o)
  - [ConfiguraÃ§Ã£o Adicional](#configuraÃ§Ã£o-adicional)
    - [PersonalizaÃ§Ã£o de Labels no Loki](#personalizaÃ§Ã£o-de-labels-no-loki)
- [DesinstalaÃ§Ã£o](#desinstalaÃ§Ã£o)

## IntroduÃ§Ã£o

A stack LGTM, da Grafana Labs, combina as melhores ferramentas open-source para fornecer visibilidade completa do sistema, consistindo em:

- **Loki**: Sistema de AgregaÃ§Ã£o de logs https://grafana.com/oss/loki/
- **Grafana**: Sistema para Interface & Dashboards https://grafana.com/oss/grafana/
- **Tempo**: Armazenamento e gerenciamento de traces distribuÃ­dos https://grafana.com/oss/tempo/
- **Mimir**: Armazenamento de mÃ©tricas a longo prazo para o Prometheus https://grafana.com/oss/mimir/


Com essa stack, temos uma soluÃ§Ã£o completa de observabilidade que cobre logs, mÃ©tricas e traces, com suporte para alta disponibilidade e escalabilidade, todos os dados ficam centralizados no Grafana para facilitar a anÃ¡lise e correlaÃ§Ã£o de eventos, e por utilizar armazenamento em bucket (object storage) como backend, a soluÃ§Ã£o se torna muito mais econÃ´mica em comparaÃ§Ã£o com outras que necessitam de bancos de dados dedicados ou discos persistentes.


## Arquitetura

![Arquitetura LGTM](./assets/images/lgtm.jpg)

A arquitetura da stack LGTM em um ambiente Kubernetes segue um fluxo bem definido de coleta, processamento e visualizaÃ§Ã£o de dados:

1. As aplicaÃ§Ãµes enviam dados de telemetria para um agente, nesse caso o OpenTelemetry Collector.

2. O OpenTelemetry Collector atua como hub central, roteando cada tipo de dado para seu backend especÃ­fico:
  * Loki: para processamento de logs
  * Mimir: para armazenamento de mÃ©tricas
  * Tempo: para anÃ¡lise de traces
3. Os dados sÃ£o armazenados em um Object Storage, com buckets dedicados para cada ferramenta

4. O Grafana Ã© a interface, aonde todos os dados sÃ£o consultados, permitindo dashboards e alertas unificados

A arquitetura tambÃ©m inclui quatro componentes opcionais:
- Prometheus: coleta mÃ©tricas personalizadas de aplicaÃ§Ãµes e do cluster e envia para o Mimir
- Kube-state-metrics: coleta mÃ©tricas (CPU/MemÃ³ria etc) dos serviÃ§os/apps atravÃ©s do API server e expÃµe para o Prometheus
- Promtail: agente que captura logs dos containers e envia para o Loki

### Requisitos de Hardware

Local:
- 2-4 CPUs
- 8 GB RAM

Ambiente de produÃ§Ã£o:
- Pode variar muito dependendo da quantidade de dados e trÃ¡fego, Ã© recomendado comeÃ§ar com uma configuraÃ§Ã£o pequena e escalar conforme necessÃ¡rio, para ambientes pequenos e mÃ©dios a seguinte configuraÃ§Ã£o Ã© recomendada (mÃ­nimo):
  - 8 CPUs
  - 24 GB RAM
  - 100 GB de espaÃ§o em disco (SSD, nÃ£o conta para backends de armazenamento)

  
## ðŸš€ InÃ­cio RÃ¡pido

### âœ¨ PrÃ©-requisitos
- [Helm v3+](https://helm.sh/docs/intro/install/)
- [kubectl](https://kubernetes.io/docs/tasks/tools/)
  - Para instalaÃ§Ã£o local: [k3s](https://k3s.io/) ou [minikube](https://minikube.sigs.k8s.io/docs/start/) kubernetes cluster configurado
- Para GCP: [gcloud CLI](https://cloud.google.com/sdk/docs/install)

> **Note**: Esse guia usa o helm chart [lgtm-distributed](https://artifacthub.io/packages/helm/grafana/lgtm-distributed) oficial do Grafana para deployment.

### OpÃ§Ã£o 1: Makefile

Para simplificar o processo de instalaÃ§Ã£o, vocÃª pode usar os comandos do Makefile:

```bash
# Clonar repositÃ³rio
git clone git@github.com:daviaraujocc/lgtm-stack.git
cd lgtm-stack
make install-local # Para testes locais, para usar GCP cloud storage use make install-gcp e defina a variÃ¡vel PROJECT_ID
```

Isso irÃ¡ instalar a stack LGTM usando os valores padrÃ£o para testes locais. Para personalizar a instalaÃ§Ã£o, vocÃª pode editar os arquivos `helm/values-lgtm.local.yaml` antes de instalar.

### OpÃ§Ã£o 2: InstalaÃ§Ã£o Manual

### ConfiguraÃ§Ã£o
```bash
# Clonar repositÃ³rio
git clone git@github.com:daviaraujocc/lgtm-stack.git
cd lgtm-stack

# Adicionar repositÃ³rios e criar namespace
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update
kubectl create ns monitoring

# Instale o prometheus operator para coleta de mÃ©tricas e CRDs
helm install prometheus-operator --version 66.3.1 -n monitoring \
  prometheus-community/kube-prometheus-stack -f helm/values-prometheus.yaml
```

### Escolha seu Ambiente

#### Local (k3s, minikube)

Para cenÃ¡rios de teste local. Utiliza armazenamento local via MinIO.

```bash
helm install lgtm --version 2.1.0 -n monitoring \
  grafana/lgtm-distributed -f helm/values-lgtm.local.yaml
```

#### ConfiguraÃ§Ã£o para ProduÃ§Ã£o na GCP

Para ambientes de produÃ§Ã£o, utilizando recursos da GCP para armazenamento e monitoramento.

1. Configure recursos GCP:

```bash
# Definir ID do projeto
export PROJECT_ID=seu-projeto-id

# Criar buckets com sufixo aleatÃ³rio
export BUCKET_SUFFIX=$(openssl rand -hex 4 | tr -d "\n")
for bucket in logs traces metrics metrics-admin; do
  gsutil mb -p ${PROJECT_ID} -c standard -l us-east1 gs://lgtm-${bucket}-${BUCKET_SUFFIX}
done

# Atualizar nomes dos buckets na configuraÃ§Ã£o
sed -i -E "s/(bucket_name:\s*lgtm-[^[:space:]]+)/\1-${BUCKET_SUFFIX}/g" helm/values-lgtm.gcp.yaml

# Criar e configurar conta de serviÃ§o
gcloud iam service-accounts create lgtm-monitoring \
    --display-name "LGTM Monitoring" \
    --project ${PROJECT_ID}

# Configurar permissÃµes
for bucket in logs traces metrics metrics-admin; do 
  gsutil iam ch serviceAccount:lgtm-monitoring@${PROJECT_ID}.iam.gserviceaccount.com:admin \
    gs://lgtm-${bucket}-${BUCKET_SUFFIX}
done

# Criar chave da conta de serviÃ§o e secret
gcloud iam service-accounts keys create key.json \
    --iam-account lgtm-monitoring@${PROJECT_ID}.iam.gserviceaccount.com
kubectl create secret generic lgtm-sa --from-file=key.json -n monitoring
```

2. Instalar stack LGTM:

VocÃª pode ajustar o arquivo values-lgtm.gcp.yaml de acordo com suas necessidades antes de aplicar, como configuraÃ§Ã£o de ingress, requisitos de recursos, etc.

```bash
helm install lgtm --version 2.1.0 -n monitoring \
  grafana/lgtm-distributed -f helm/values-lgtm.gcp.yaml
```

## InstalaÃ§Ã£o de DependÃªncias (opcional)

```bash
# Instalar Promtail para coletar logs dos containers (opcional)
## Ambiente Docker
kubectl apply -f manifests/promtail.docker.yaml
## Ambiente CRI
# kubectl apply -f manifests/promtail.cri.yaml
```

## Testando

Depois de instalar a stack LGTM, verifique se todos os componentes estÃ£o em execuÃ§Ã£o:

```bash
# Verificar pods em execuÃ§Ã£o
kubectl get pods -n monitoring

# Para checar logs dos componentes

# Loki
kubectl logs -l app.kubernetes.io/name=loki -n monitoring

# Tempo
kubectl logs -l app.kubernetes.io/name=tempo -n monitoring

# Mimir
kubectl logs -l app.kubernetes.io/name=mimir -n monitoring
```

Siga as instruÃ§Ãµes abaixo para acessar e testar cada componente:

### Acesso ao Grafana
```bash
# Acessar dashboard
kubectl port-forward svc/lgtm-grafana 3000:80 -n monitoring

# Obter senha
kubectl get secret --namespace monitoring lgtm-grafana -o jsonpath="{.data.admin-password}" | base64 --decode
```
- UsuÃ¡rio padrÃ£o: `admin`
- URL de acesso: http://localhost:3000

### Enviando Dados

ApÃ³s a instalaÃ§Ã£o, verifique se cada componente estÃ¡ funcionando corretamente:

#### Loki (Logs)
Teste a ingestÃ£o e consulta de logs:

```bash
# Encaminhar porta do Loki
kubectl port-forward svc/lgtm-loki-distributor 3100:3100 -n monitoring

# Enviar log de teste com timestamp e labels
curl -XPOST http://localhost:3100/loki/api/v1/push -H "Content-Type: application/json" -d '{
  "streams": [{
    "stream": { "app": "test", "level": "info" },
    "values": [[ "'$(date +%s)000000000'", "Mensagem de log de teste" ]]
  }]
}'
```

Para verificar:
1. Abra o Grafana (http://localhost:3000)
2. VÃ¡ para Explore > Selecione fonte de dados Loki
3. Consulte usando labels: `{app="test", level="info"}`
4. VocÃª deverÃ¡ ver sua mensagem de teste nos resultados

Se vocÃª instalou o Promtail, vocÃª tambÃ©m pode verificar os logs dos containers na aba Explore.

#### Tempo (Traces)

Como o tempo Ã© compatÃ­vel com o protocolo OTLP da OpenTelemetry, usaremos o Jaeger Trace Generator, uma ferramenta que gera traces de exemplo que tambÃ©m envia os dados usando OTLP.

```bash
# Encaminhar porta do Tempo
kubectl port-forward svc/lgtm-tempo-distributor 4318:4318 -n monitoring

# Gerar traces de exemplo com nome de serviÃ§o 'test'
docker run --add-host=host.docker.internal:host-gateway --env=OTEL_EXPORTER_OTLP_ENDPOINT=http://host.docker.internal:4318 jaegertracing/jaeger-tracegen -service test -traces 10
```

Para verificar:
1. VÃ¡ para Explore > Selecione fonte de dados Tempo
2. Pesquise pelo Nome do ServiÃ§o: 'test'
3. VocÃª deverÃ¡ ver 10 traces com diferentes spans

#### Mimir (MÃ©tricas)

Como temos uma instÃ¢ncia do Prometheus rodando dentro do cluster enviando mÃ©tricas bÃ¡sicas (CPU/MemÃ³ria) para o Mimir, vocÃª pode verificar as mÃ©tricas jÃ¡ no Grafana:

1. Acesse o Grafana
2. VÃ¡ para Explore > Selecione a fonte de dados Mimir
3. Experimente estas consultas de exemplo:
   - `rate(container_cpu_usage_seconds_total[5m])` - Uso de CPU
   - `container_memory_usage_bytes` - Uso de memÃ³ria do container

VocÃª tambÃ©m pode fazer o push de mÃ©tricas personalizadas para o Mimir usando o Prometheus Pushgateway, para o endpoint `http://lgtm-mimir-nginx.monitoring:80/api/v1/push`.

## OpenTelemetry

OpenTelemetry Ã© um conjunto de APIs, bibliotecas, agentes e instrumentaÃ§Ã£o para fornecer observabilidade para software nativo de nuvem. Consiste em trÃªs componentes principais:

- **OpenTelemetry SDK**: Bibliotecas para instrumentar aplicaÃ§Ãµes para coletar dados de telemetria (traces, mÃ©tricas, logs).
- **OpenTelemetry Collector**: Um agente agnÃ³stico de fornecedor que coleta, processa e exporta dados de telemetria para backends.
- **OpenTelemetry Protocol (OTLP)**: Um padrÃ£o para troca de dados de telemetria entre aplicaÃ§Ãµes e backends.

Nesta configuraÃ§Ã£o, usaremos o OpenTelemetry Collector para rotear dados de telemetria para os backends apropriados (Loki, Tempo, Mimir).

### OpenTelemetry Collector

Para instalar o OpenTelemetry Collector:

```bash
# Instalar OpenTelemetry Collector
kubectl apply -f manifests/otel-collector.yaml
```

Verifique se o collector estÃ¡ em execuÃ§Ã£o:

```bash
kubectl get pods -l app=otel-collector
kubectl logs -l app=otel-collector
```

### IntegraÃ§Ã£o com Flask App

Usaremos uma aplicaÃ§Ã£o Flask prÃ©-instrumentada (cÃ³digo fonte em `flask-app/`) que gera traces, mÃ©tricas e logs usando OpenTelemetry.

A aplicaÃ§Ã£o expÃµe um endpoint `/random` que retorna nÃºmeros aleatÃ³rios e gera dados de telemetria. O endpoint padrÃ£o usado para enviar dados de telemetria serÃ¡ `http://otel-collector:4318`.

1. Implante a aplicaÃ§Ã£o de exemplo:
```bash
# Implantar aplicaÃ§Ã£o de exemplo
kubectl apply -f manifests/app/flask-app.yaml
```

2. Verifique a implantaÃ§Ã£o da aplicaÃ§Ã£o:
```bash
kubectl get pods -l app=flask-app 
kubectl get svc flask-app-service 
```

3. Aplique o PodMonitor para coleta de mÃ©tricas:
```bash
kubectl apply -f manifests/app/podmonitor.yaml
```

### Testando a integraÃ§Ã£o

1. Gere trÃ¡fego para a aplicaÃ§Ã£o:
```bash
# Obtenha a URL da aplicaÃ§Ã£o
# Port-forward da aplicaÃ§Ã£o
kubectl port-forward svc/flask-app 8000:8000 -n monitoring

# Envie requisiÃ§Ãµes para gerar dados de telemetria
for i in {1..50}; do
  curl http://localhost:8000/random
  sleep 0.5
done
```

2. Verifique os dados de telemetria gerados no Grafana:

**Traces (Tempo):**

1. VÃ¡ para Explore > Selecione a fonte de dados Tempo

2. Pesquise por Service Name: flask-app

3. VocÃª deverÃ¡ ver traces com operaÃ§Ãµes GET /random

**MÃ©tricas (Mimir):**

1. VÃ¡ para Explore > Selecione a fonte de dados Mimir

2. Experimente estas consultas:
```promql
# Contagem total de requisiÃ§Ãµes
rate(request_count_total[5m])
```

**Logs (Loki):**

1. VÃ¡ para Explore > Selecione a fonte de dados Loki

2. Consulte usando labels:

```logql
{job="flask-app"}
```
VocÃª deverÃ¡ ver logs estruturados da aplicaÃ§Ã£o.

#### ConfiguraÃ§Ã£o Adicional

##### PersonalizaÃ§Ã£o de Labels no Loki

Caso vocÃª tenha novos labels que deseja adicionar aos logs no Loki atravÃ©s do OpenTelemetry Collector, vocÃª precisa realizar a seguinte configuraÃ§Ã£o:

1. Edite o ConfigMap `otel-collector-config`
2. Localize a seÃ§Ã£o `processors.attributes/loki`
3. Adicione seus labels personalizados Ã  lista `loki.attribute.labels`:

```yaml
processors:
  attributes/loki:
    actions:
      - action: insert
        key: loki.format
        value: raw
      - action: insert
        key: loki.attribute.labels
        value: facility, level, source, host, app, namespace, pod, container, job, seu_label
```

> ApÃ³s modificar o ConfigMap, reinicie o pod do collector para aplicar as mudanÃ§as:
> ```bash
> kubectl rollout restart daemonset/otel-collector -n monitoring
> ```

## DesinstalaÃ§Ã£o

```bash
# Usando makefile
make uninstall

# ou manualmente

# Remover stack LGTM
helm uninstall lgtm -n monitoring

# Remover prometheus operator 
helm uninstall prometheus-operator -n monitoring

# Remover namespace
kubectl delete ns monitoring

# Remover promtail & otel-collector 
kubectl delete -f manifests/promtail.yaml
kubectl delete -f manifests/otel-collector.yaml

# Para ambiente GCP, limpeza:
for bucket in logs traces metrics metrics-admin; do
  gsutil rm -r gs://lgtm-${bucket}-${BUCKET_SUFFIX}
done

gcloud iam service-accounts delete lgtm-monitoring@${PROJECT_ID}.iam.gserviceaccount.com
```