# ğŸ” Stack LGTM para Kubernetes

<br>

<div align="center">
    <a href="README.md">ğŸ‡ºğŸ‡¸ English</a> | <a href="README.pt-br.md">ğŸ‡§ğŸ‡· PortuguÃªs (Brasil)</a>
</div>
<br>

Guia completo de implantaÃ§Ã£o de uma plataforma de observabilidade para Kubernetes. A stack LGTM, da Grafana Labs, combina as melhores ferramentas open-source para fornecer visibilidade abrangente do sistema, consistindo em:

- **Loki**: Armazenamento e gerenciamento de logs
- **Tempo**: Armazenamento e gerenciamento de traces distribuÃ­dos
- **Mimir**: Armazenamento de mÃ©tricas de longo prazo
- **Grafana**: Interface e Dashboards

## Arquitetura

A arquitetura da stack LGTM integra todos os componentes para fornecer uma soluÃ§Ã£o completa de observabilidade:

![Arquitetura LGTM](./assets/images/lgtm.jpg)

Cada componente (Loki, Grafana, Tempo, Mimir) Ã© executado no Kubernetes com seu prÃ³prio backend de armazenamento. Por exemplo, estamos usando o GCP Cloud Storage como exemplo, mas eles tambÃ©m suportam AWS/Azure como backends. Para desenvolvimento local, podemos usar o MinIO.

A stack tambÃ©m inclui trÃªs componentes opcionais:
- Prometheus: coleta mÃ©tricas do cluster (CPU/MemÃ³ria) e envia para o Mimir
- Promtail: agente que captura logs de contÃªineres e envia para o Loki
- OpenTelemetry Collector: roteia todos os dados de telemetria para os backends apropriados, atuando como um hub central

## InÃ­cio RÃ¡pido

### âœ¨ PrÃ©-requisitos
- Helm v3+ (gerenciador de pacotes)
- kubectl
- Para GCP: CLI gcloud com permissÃµes de proprietÃ¡rio do projeto

### Requisitos de Hardware

Desenvolvimento local:
- 2-4 CPUs
- 8 GB RAM
- 50 GB de espaÃ§o em disco

ConfiguraÃ§Ã£o de produÃ§Ã£o:
- Pode variar muito dependendo da quantidade de dados e trÃ¡fego, Ã© recomendado comeÃ§ar com uma configuraÃ§Ã£o pequena e escalar conforme necessÃ¡rio, para configuraÃ§Ãµes pequenas com 20 milhÃµes de logs consumidos por dia, 11 mil mÃ©tricas por minuto e 3 milhÃµes de spans por dia, a seguinte configuraÃ§Ã£o Ã© recomendada:
  - 8 CPUs
  - 24 GB RAM
  - 100 GB de espaÃ§o em disco (SSD, nÃ£o conta para backends de armazenamento)

### ConfiguraÃ§Ã£o
```bash
# Adicionar repositÃ³rios e criar namespace
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update
kubectl create ns monitoring
```

### Escolha Seu Ambiente

#### Desenvolvimento Local (k3s, minikube)

Para cenÃ¡rios de teste e desenvolvimento local. Usa armazenamento local via MinIO.

```bash
helm install lgtm --version 2.1.0 -n monitoring \
  grafana/lgtm-distributed -f helm/values-lgtm.local.yaml
```

#### ConfiguraÃ§Ã£o GCP ProduÃ§Ã£o

Para ambientes de produÃ§Ã£o, usando recursos GCP para armazenamento e monitoramento.

1. Configure os recursos GCP:

```bash
# Configure seu ID de projeto
export PROJECT_ID=your-project-id

# Crie buckets com sufixo aleatÃ³rio
export BUCKET_SUFFIX=$(openssl rand -hex 4 | tr -d "\n")
for bucket in logs traces metrics metrics-admin; do
  gsutil mb -p ${PROJECT_ID} -c standard -l us-east1 gs://lgtm-${bucket}-${BUCKET_SUFFIX}
done

# Atualize os nomes dos buckets na configuraÃ§Ã£o
sed -i -E "s/(bucket_name:\s*lgtm-[^[:space:]]+)/\1-${BUCKET_SUFFIX}/g" helm/values-lgtm.gcp.yaml

# Crie e configure a conta de serviÃ§o
gcloud iam service-accounts create lgtm-monitoring \
    --display-name "LGTM Monitoring" \
    --project ${PROJECT_ID}

# Configure permissÃµes
for bucket in logs traces metrics metrics-admin; do 
  gsutil iam ch serviceAccount:lgtm-monitoring@${PROJECT_ID}.iam.gserviceaccount.com:admin \
    gs://lgtm-${bucket}-${BUCKET_SUFFIX}
done

# Crie a chave da conta de serviÃ§o e o secret
gcloud iam service-accounts keys create key.json \
    --iam-account lgtm-monitoring@${PROJECT_ID}.iam.gserviceaccount.com
kubectl create secret generic lgtm-sa --from-file=key.json -n monitoring
```

2. Instale a stack LGTM:

Altere o values-lgtm.gcp.yaml de acordo com suas necessidades antes de aplicar, como configuraÃ§Ã£o de ingress, requisitos de recursos, etc.

```bash
helm install lgtm --version 2.1.0 -n monitoring \
  grafana/lgtm-distributed -f helm/values-lgtm.gcp.yaml
```

## Instalar dependÃªncias

```bash
# Instalar Promtail para coletar logs de contÃªineres
# Verifique se vocÃª estÃ¡ usando runtime Docker ou CRI-O
## Runtime Docker
kubectl apply -f manifests/promtail.docker.yaml
## Runtime CRI-O
kubectl apply -f manifests/promtail.cri.yaml

# Instalar prometheus operator para coleta de mÃ©tricas
helm install prometheus-operator --version 66.3.1 -n monitoring \
  prometheus-community/kube-prometheus-stack -f helm/values-prometheus.yaml

# Instalar dashboards kubernetes para grafana
kubectl apply -f manifests/kubernetes-dashboards.yaml
```

## Testes

### Acessar Grafana
```bash
# Acessar dashboard
kubectl port-forward svc/lgtm-grafana 3000:80 -n monitoring

# Obter credenciais de senha
kubectl get secret --namespace monitoring lgtm-grafana -o jsonpath="{.data.admin-password}" | base64 --decode
```
- UsuÃ¡rio padrÃ£o: `admin`
- URL de acesso: http://localhost:3000
- Verifique os dashboards padrÃ£o do Grafana e a aba Explore

### Teste dos Componentes

ApÃ³s a instalaÃ§Ã£o, verifique se cada componente estÃ¡ funcionando corretamente:

#### Loki (Logs)
Teste a ingestÃ£o e consulta de logs:

```bash
# Encaminhar porta do Loki
kubectl port-forward svc/lgtm-loki-distributor 3100:3100 -n monitoring

# Enviar log de teste com timestamp e labels
curl -XPOST http://localhost:3100/loki/api/v1/push -H "Content-Type: application/json" -d '{
  "streams": [{
    "stream": { "app": "test", "level": "info" },
    "values": [[ "'$(date +%s)000000000'", "Mensagem de log de teste" ]]
  }]
}'
```

Para verificar:
1. Abra o Grafana (http://localhost:3000)
2. VÃ¡ para Explore > Selecione a fonte de dados Loki
3. Consulte usando labels: `{app="test", level="info"}`
4. VocÃª deve ver sua mensagem de teste nos resultados

Se vocÃª instalou o promtail, vocÃª tambÃ©m pode verificar os logs dos contÃªineres na aba Explore.

#### Tempo (Traces)

```bash
# Encaminhar porta do Tempo
kubectl port-forward svc/lgtm-tempo-distributor 4318:4318 -n monitoring

# Gerar traces de exemplo com nome de serviÃ§o 'test'
docker run --add-host=host.docker.internal:host-gateway --env=OTEL_EXPORTER_OTLP_ENDPOINT=http://host.docker.internal:4318 jaegertracing/jaeger-tracegen -service test -traces 10
```

Para verificar:
1. VÃ¡ para Explore > Selecione a fonte de dados Tempo
2. Pesquise por Nome do ServiÃ§o: 'test'
3. VocÃª deve ver 10 traces com diferentes spans

#### Mimir (MÃ©tricas)

Se o operador Prometheus foi instalado, temos uma instÃ¢ncia rodando dentro do cluster enviando mÃ©tricas bÃ¡sicas (CPU/MemÃ³ria) para o Mimir, vocÃª pode verificar as mÃ©tricas jÃ¡ no Grafana:

1. Acesse o Grafana
2. VÃ¡ para Explore > Selecione a fonte de dados Mimir
3. Experimente estas consultas de exemplo:
   - `rate(container_cpu_usage_seconds_total[5m])` - Uso de CPU
   - `container_memory_usage_bytes` - Uso de memÃ³ria do contÃªiner

### Dicas de SoluÃ§Ã£o de Problemas

Se os componentes nÃ£o estiverem funcionando:

1. Verifique o status dos pods:
```bash
kubectl get pods -n monitoring
```

2. Visualize os logs dos componentes:
```bash
# Para o Loki
kubectl logs -l app.kubernetes.io/name=loki -n monitoring

# Para o Tempo
kubectl logs -l app.kubernetes.io/name=tempo -n monitoring

# Para o Mimir
kubectl logs -l app.kubernetes.io/name=mimir -n monitoring
```

> Consulte a documentaÃ§Ã£o oficial de cada componente para mais etapas de soluÃ§Ã£o de problemas.

## Componentes Adicionais

### OpenTelemetry Collector

O OpenTelemetry Collector atua como um hub central para todos os dados de telemetria:

```bash
# Instalar OpenTelemetry Collector
kubectl apply -f manifests/otel-collector.yaml
```

#### ConfiguraÃ§Ã£o de Endpoints

| Tipo de Dados | Protocolo | Endpoint | Porta |
|---------------|-----------|----------|-------|
| Traces | gRPC | otel-collector | 4317 |
| Traces | HTTP | otel-collector | 4318 |
| Metrics | gRPC | otel-collector | 4317 |
| Metrics | HTTP | otel-collector | 4318 |
| Logs | HTTP | otel-collector | 3100 |

#### IntegraÃ§Ã£o com Componentes

1. **ConfiguraÃ§Ã£o do Promtail**
   - Edite `manifests/promtail.yaml`
   - Atualize a seÃ§Ã£o clients:
   ```yaml
   clients:
     - url: http://otel-collector:3100/loki/api/v1/push
   ```

2. **IntegraÃ§Ã£o com AplicaÃ§Ãµes**
   - Use SDKs OpenTelemetry
   - Configure endpoint: `otel-collector:4317` para gRPC
   - Para HTTP: `http://otel-collector:4318`

#### VerificaÃ§Ã£o

Verifique se o collector estÃ¡ recebendo dados:
```bash
# Visualizar logs do collector
kubectl logs -l app=otel-collector -n monitoring
```

#### ConfiguraÃ§Ã£o Extra

##### PersonalizaÃ§Ã£o de Labels do Loki

Para adicionar novos labels aos logs no Loki atravÃ©s do OpenTelemetry Collector:

1. Edite o ConfigMap `otel-collector-config`
2. Localize a seÃ§Ã£o `processors.attributes/loki`
3. Adicione seus labels personalizados Ã  lista `loki.attribute.labels`:

```yaml
processors:
  attributes/loki:
    actions:
      - action: insert
        key: loki.format
        value: raw
      - action: insert
        key: loki.attribute.labels
        value: facility, level, source, host, app, namespace, pod, container, job, your_label
```

> ApÃ³s modificar o ConfigMap, reinicie o pod do collector para aplicar as mudanÃ§as:
> ```bash
> kubectl rollout restart daemonset/otel-collector -n monitoring
> ```

## DesinstalaÃ§Ã£o

```bash
# Remover stack LGTM
helm uninstall lgtm -n monitoring

# Remover prometheus operator 
helm uninstall prometheus-operator -n monitoring

# Remover namespace
kubectl delete ns monitoring

# Remover promtail & otel-collector 
kubectl delete -f manifests/promtail.yaml
kubectl delete -f manifests/otel-collector.yaml

# Para configuraÃ§Ã£o GCP, limpeza:
for bucket in logs traces metrics metrics-admin; do
  gsutil rm -r gs://lgtm-${bucket}-${BUCKET_SUFFIX}
done

gcloud iam service-accounts delete lgtm-monitoring@${PROJECT_ID}.iam.gserviceaccount.com
```
````
