<br>

<div align="center">
    <a href="README.md">üá∫üá∏ English</a> | <a href="README.pt-br.md">üáßüá∑ Portugu√™s (Brasil)</a>
</div>
<br>

# üîç Stack LGTM para Kubernetes

## Introdu√ß√£o

A stack LGTM, da Grafana Labs, combina as melhores ferramentas open-source para fornecer visibilidade completa do sistema, consistindo em:

- **Loki**: Armazenamento e gerenciamento de logs
- **Tempo**: Armazenamento e gerenciamento de traces distribu√≠dos
- **Mimir**: Armazenamento de m√©tricas a longo prazo
- **Grafana**: Interface & Dashboards

Com essa stack, temos uma solu√ß√£o completa de observabilidade que cobre logs, m√©tricas e traces, com suporte para alta disponibilidade e escalabilidade, todos os dados ficam centralizados no Grafana para facilitar a an√°lise e correla√ß√£o de eventos, e por utilizar armazenamento em bucket (object storage) como backend, a solu√ß√£o se torna muito mais econ√¥mica em compara√ß√£o com outras que necessitam de bancos de dados dedicados ou discos persistentes, como a ELK Stack.

<div align="center">
<h3> Esse guia ir√° te ajudar a configurar a stack LGTM no seu ambiente Kubernetes, seja para desenvolvimento local ou produ√ß√£o, tamb√©m como configurar um coletor de open telemetry para direcionar todos os dados de telemetria para os backends apropriados.</h3>
</div>

## Arquitetura

![Arquitetura LGTM](./assets/images/lgtm.jpg)

Cada componente (Loki, Grafana, Tempo, Mimir) roda no Kubernetes com seu pr√≥prio backend de armazenamento. Como exemplo, estamos usando o Cloud Storage da GCP, mas a stack tamb√©m suportam AWS (s3)/Azure (blob storage) como backends, para desenvolvimento/teste local podemos usar o MinIO.

A arquitetura tamb√©m inclui tr√™s componentes opcionais:
- Prometheus: coleta m√©tricas do cluster (CPU/Mem√≥ria) e envia para o Mimir
- Promtail: agente que captura logs dos containers e envia para o Loki
- OpenTelemetry Collector: encaminha todos os dados de telemetria para os backends apropriados, atuando como um hub central

### Requisitos de Hardware

Desenvolvimento local:
- 2-4 CPUs
- 8 GB RAM
- 50 GB de espa√ßo em disco

Ambiente de produ√ß√£o:
- Pode variar muito dependendo da quantidade de dados e tr√°fego, √© recomendado come√ßar com uma configura√ß√£o pequena e escalar conforme necess√°rio, para ambientes pequenos e m√©dios a seguinte configura√ß√£o √© recomendada (m√≠nimo):
  - 8 CPUs
  - 24 GB RAM
  - 100 GB de espa√ßo em disco (SSD, n√£o conta para backends de armazenamento)

## Sum√°rio

- [In√≠cio R√°pido](#in√≠cio-r√°pido)
  - [Pr√©-requisitos](#-pr√©-requisitos)
  - [Instala√ß√£o](#instala√ß√£o)
    - [Op√ß√£o 1: Makefile](#op√ß√£o-1-makefile)
    - [Op√ß√£o 2: Instala√ß√£o Manual](#op√ß√£o-2-instala√ß√£o-manual)
- [Instala√ß√£o de Depend√™ncias](#instala√ß√£o-de-depend√™ncias-opcional)
- [Testando](#testando)
  - [Acesso ao Grafana](#acesso-ao-grafana)
  - [Enviando Dados](#enviando-dados)
    - [Loki (Logs)](#-loki-logs)
    - [Tempo (Traces)](#tempo-traces)
    - [Mimir (M√©tricas)](#mimir-m√©tricas)
- [OpenTelemetry](#opentelemetry)
  - [OpenTelemetry Collector](#opentelemetry-collector)
    - [Guia de Integra√ß√£o](#guia-de-integra√ß√£o)
      - [Endpoints](#endpoints)
      - [Configura√ß√£o Extra](#configura√ß√£o-extra)
        - [Personaliza√ß√£o de Labels do Loki](#personaliza√ß√£o-de-labels-do-loki)
- [Desinstala√ß√£o](#desinstala√ß√£o)
  
## In√≠cio R√°pido

### ‚ú® Pr√©-requisitos
- [Helm v3+](https://helm.sh/docs/intro/install/)
- [kubectl](https://kubernetes.io/docs/tasks/tools/)
  - Para instala√ß√£o local: [k3s](https://k3s.io/) ou [minikube](https://minikube.sigs.k8s.io/docs/start/) kubernetes cluster configurado
- Para GCP: [gcloud CLI](https://cloud.google.com/sdk/docs/install)

### Op√ß√£o 1: Makefile

Para simplificar o processo de instala√ß√£o, voc√™ pode usar os comandos do Makefile:

```bash
# Clonar reposit√≥rio
git clone git@github.com:daviaraujocc/lgtm-stack.git
cd lgtm-stack
make install-local # Para testes locais, para usar GCP cloud storage use make install-gcp e defina a vari√°vel PROJECT_ID
```

Isso ir√° instalar a stack LGTM usando a [lgtm-distributed](https://artifacthub.io/packages/helm/grafana/lgtm-distributed) helm chart, com os valores padr√£o para testes locais. Para personalizar a instala√ß√£o, voc√™ pode editar os arquivos `helm/values-lgtm.local.yaml` antes de instalar.

### Op√ß√£o 2: Instala√ß√£o Manual

### Configura√ß√£o
```bash
# Adicionar reposit√≥rios e criar namespace
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update
kubectl create ns monitoring

# Instale o prometheus operator para coleta de m√©tricas e CRDs
helm install prometheus-operator --version 66.3.1 -n monitoring \
  prometheus-community/kube-prometheus-stack -f helm/values-prometheus.yaml
```

### Escolha seu Ambiente

#### Desenvolvimento Local (k3s, minikube)

Para cen√°rios de teste e desenvolvimento local. Utiliza armazenamento local via MinIO.

```bash
helm install lgtm --version 2.1.0 -n monitoring \
  grafana/lgtm-distributed -f helm/values-lgtm.local.yaml
```

#### Configura√ß√£o para Produ√ß√£o na GCP

Para ambientes de produ√ß√£o, utilizando recursos da GCP para armazenamento e monitoramento.

1. Configure recursos GCP:

```bash
# Definir ID do projeto
export PROJECT_ID=seu-projeto-id

# Criar buckets com sufixo aleat√≥rio
export BUCKET_SUFFIX=$(openssl rand -hex 4 | tr -d "\n")
for bucket in logs traces metrics metrics-admin; do
  gsutil mb -p ${PROJECT_ID} -c standard -l us-east1 gs://lgtm-${bucket}-${BUCKET_SUFFIX}
done

# Atualizar nomes dos buckets na configura√ß√£o
sed -i -E "s/(bucket_name:\s*lgtm-[^[:space:]]+)/\1-${BUCKET_SUFFIX}/g" helm/values-lgtm.gcp.yaml

# Criar e configurar conta de servi√ßo
gcloud iam service-accounts create lgtm-monitoring \
    --display-name "LGTM Monitoring" \
    --project ${PROJECT_ID}

# Configurar permiss√µes
for bucket in logs traces metrics metrics-admin; do 
  gsutil iam ch serviceAccount:lgtm-monitoring@${PROJECT_ID}.iam.gserviceaccount.com:admin \
    gs://lgtm-${bucket}-${BUCKET_SUFFIX}
done

# Criar chave da conta de servi√ßo e secret
gcloud iam service-accounts keys create key.json \
    --iam-account lgtm-monitoring@${PROJECT_ID}.iam.gserviceaccount.com
kubectl create secret generic lgtm-sa --from-file=key.json -n monitoring
```

2. Instalar stack LGTM:

Ajuste o arquivo values-lgtm.gcp.yaml de acordo com suas necessidades antes de aplicar, como configura√ß√£o de ingress, requisitos de recursos, etc.

```bash
helm install lgtm --version 2.1.0 -n monitoring \
  grafana/lgtm-distributed -f helm/values-lgtm.gcp.yaml
```

## Instala√ß√£o de Depend√™ncias (opcional)

```bash
# Instalar Promtail para coletar logs dos containers (opcional)
## Ambiente Docker
kubectl apply -f manifests/promtail.docker.yaml
## Ambiente CRI
kubectl apply -f manifests/promtail.cri.yaml

# Instalar dashboards do kubernetes
kubectl apply -f manifests/kubernetes-dashboards.yaml
```

## Testando

Depois de instalar a stack LGTM, verifique se todos os componentes est√£o em execu√ß√£o:

```bash
# Verificar pods em execu√ß√£o
kubectl get pods -n monitoring

# Para checar logs dos componentes

# Loki
kubectl logs -l app.kubernetes.io/name=loki -n monitoring

# Tempo
kubectl logs -l app.kubernetes.io/name=tempo -n monitoring

# Mimir
kubectl logs -l app.kubernetes.io/name=mimir -n monitoring
```

Siga as instru√ß√µes abaixo para acessar e testar cada componente:

### Acesso ao Grafana
```bash
# Acessar dashboard
kubectl port-forward svc/lgtm-grafana 3000:80 -n monitoring

# Obter senha
kubectl get secret --namespace monitoring lgtm-grafana -o jsonpath="{.data.admin-password}" | base64 --decode
```
- Usu√°rio padr√£o: `admin`
- URL de acesso: http://localhost:3000

### Enviando Dados

Ap√≥s a instala√ß√£o, verifique se cada componente est√° funcionando corretamente:

#### Loki (Logs)
Teste a ingest√£o e consulta de logs:

```bash
# Encaminhar porta do Loki
kubectl port-forward svc/lgtm-loki-distributor 3100:3100 -n monitoring

# Enviar log de teste com timestamp e labels
curl -XPOST http://localhost:3100/loki/api/v1/push -H "Content-Type: application/json" -d '{
  "streams": [{
    "stream": { "app": "test", "level": "info" },
    "values": [[ "'$(date +%s)000000000'", "Mensagem de log de teste" ]]
  }]
}'
```

Para verificar:
1. Abra o Grafana (http://localhost:3000)
2. V√° para Explore > Selecione fonte de dados Loki
3. Consulte usando labels: `{app="test", level="info"}`
4. Voc√™ dever√° ver sua mensagem de teste nos resultados

Se voc√™ instalou o Promtail, voc√™ tamb√©m pode verificar os logs dos containers na aba Explore.

#### Tempo (Traces)

Como o tempo √© compat√≠vel com o protocolo OTLP da OpenTelemetry, usaremos o Jaeger Trace Generator, uma ferramenta que gera traces de exemplo que tamb√©m envia os dados usando OTLP.

```bash
# Encaminhar porta do Tempo
kubectl port-forward svc/lgtm-tempo-distributor 4318:4318 -n monitoring

# Gerar traces de exemplo com nome de servi√ßo 'test'
docker run --add-host=host.docker.internal:host-gateway --env=OTEL_EXPORTER_OTLP_ENDPOINT=http://host.docker.internal:4318 jaegertracing/jaeger-tracegen -service test -traces 10
```

Para verificar:
1. V√° para Explore > Selecione fonte de dados Tempo
2. Pesquise pelo Nome do Servi√ßo: 'test'
3. Voc√™ dever√° ver 10 traces com diferentes spans

#### Mimir (M√©tricas)

Como temos uma inst√¢ncia do Prometheus rodando dentro do cluster enviando m√©tricas b√°sicas (CPU/Mem√≥ria) para o Mimir, voc√™ pode verificar as m√©tricas j√° no Grafana:

1. Acesse o Grafana
2. V√° para Explore > Selecione fonte de dados Mimir
3. Experimente estas consultas de exemplo:
   - `rate(container_cpu_usage_seconds_total[5m])` - Uso de CPU
   - `container_memory_usage_bytes` - Uso de mem√≥ria do container

Voc√™ tamb√©m pode fazer o push de m√©tricas personalizadas para o Mimir usando o Prometheus Pushgateway, para o endpoint `http://lgtm-mimir-nginx.monitoring:80/api/v1/push`.

## OpenTelemetry

OpenTelemetry √© um conjunto de APIs, bibliotecas, agentes e instrumenta√ß√£o para fornecer observabilidade para software nativo de nuvem. Consiste em tr√™s componentes principais:

- **OpenTelemetry SDK**: Bibliotecas para instrumentar aplica√ß√µes para coletar dados de telemetria (traces, m√©tricas, logs).
- **OpenTelemetry Collector**: Um agente agn√≥stico de fornecedor que coleta, processa e exporta dados de telemetria para backends.
- **OpenTelemetry Protocol (OTLP)**: Um padr√£o para troca de dados de telemetria entre aplica√ß√µes e backends.

Neste setup, usaremos o OpenTelemetry Collector para direcionar os dados de telemetria para os backends apropriados (Loki, Tempo, Mimir).

### OpenTelemetry Collector

O OpenTelemetry Collector atua como um hub central para todos os dados de telemetria, direcionando-os para os backends apropriados (Loki, Tempo, Mimir).

Para instalar o OpenTelemetry Collector:

```bash
# Instalar OpenTelemetry Collector
kubectl apply -f manifests/otel-collector.yaml
```

Verifique se o collector est√° em execu√ß√£o:

```bash
kubectl get pods -l app=otel-collector
```

#### Guia de Integra√ß√£o

O OpenTelemetry Collector automaticamente direciona os dados para o backend apropriado com base no tipo de dado e porta. Aqui est√° como utiliz√°-lo:

Para logs:
Direcione seus coletores de logs ou aplica√ß√µes usando a biblioteca do Loki para `http://otel-collector:3100`.

Para traces e m√©tricas:
Configure seu SDK OpenTelemetry para usar:
- Endpoint gRPC: `otel-collector:4317`
- Endpoint HTTP: `http://otel-collector:4318`

##### Endpoints

| Tipo de Dado | Protocolo | Endpoint | Porta |
|--------------|-----------|----------|-------|
| Traces | gRPC | otel-collector | 4317 |
| Traces | HTTP | otel-collector | 4318 |
| M√©tricas | gRPC | otel-collector | 4317 |
| M√©tricas | HTTP | otel-collector | 4318 |
| Logs | HTTP | otel-collector | 3100 |

#### Configura√ß√£o Extra

##### Personaliza√ß√£o de Labels do Loki

Caso voc√™ tenha novos labels que deseja adicionar aos logs no Loki atrav√©s do OpenTelemetry Collector, voc√™ precisa realizar a seguinte configura√ß√£o:

1. Edite o ConfigMap `otel-collector-config`
2. Localize a se√ß√£o `processors.attributes/loki`
3. Adicione seus labels personalizados √† lista `loki.attribute.labels`:

```yaml
processors:
  attributes/loki:
    actions:
      - action: insert
        key: loki.format
        value: raw
      - action: insert
        key: loki.attribute.labels
        value: facility, level, source, host, app, namespace, pod, container, job, seu_label
```

> Ap√≥s modificar o ConfigMap, reinicie o pod do collector para aplicar as mudan√ßas:
> ```bash
> kubectl rollout restart daemonset/otel-collector -n monitoring
> ```

## Desinstala√ß√£o

```bash
# Usando makefile
make uninstall

# ou manualmente

# Remover stack LGTM
helm uninstall lgtm -n monitoring

# Remover prometheus operator 
helm uninstall prometheus-operator -n monitoring

# Remover namespace
kubectl delete ns monitoring

# Remover promtail & otel-collector 
kubectl delete -f manifests/promtail.yaml
kubectl delete -f manifests/otel-collector.yaml

# Para ambiente GCP, limpeza:
for bucket in logs traces metrics metrics-admin; do
  gsutil rm -r gs://lgtm-${bucket}-${BUCKET_SUFFIX}
done

gcloud iam service-accounts delete lgtm-monitoring@${PROJECT_ID}.iam.gserviceaccount.com
```